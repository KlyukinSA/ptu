{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyJhlwgCwdeT",
        "outputId": "6b5a4fb1-19d3-4719-8205-ddc4e7e349f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/dmitryyemelyanov/chinese-traffic-signs?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 185M/185M [00:02<00:00, 64.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download('dmitryyemelyanov/chinese-traffic-signs')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/root/.cache/kagglehub/datasets/dmitryyemelyanov/chinese-traffic-signs/versions/2'"
      ],
      "metadata": {
        "id": "94Sw7AM9xQO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# small_shape=(224, 224)\n",
        "small_shape=(48, 48)"
      ],
      "metadata": {
        "id": "dwhtm4s-1ol5"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense ,Flatten ,Conv2D ,MaxPooling2D ,Dropout ,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping ,ReduceLROnPlateau ,ModelCheckpoint\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "J2c6Nlljwrxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = path+'/images/'\n",
        "df = pd.read_csv(path+\"/annotations.csv\")"
      ],
      "metadata": {
        "id": "lsTVDXbIxHWU"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = df[np.array(['file_name', 'x1', 'y1', 'x2', 'y2'])].values\n",
        "images = []\n",
        "for file_path, x1, y1, x2, y2 in file_paths:\n",
        "    image_path = os.path.join(data_dir, file_path)\n",
        "    image = Image.open(image_path)\n",
        "    si = np.array(image)[x1:x2, y1:y2]\n",
        "    images.append(Image.fromarray(si).resize(small_shape))\n",
        "\n",
        "# file_paths = df['file_name'].values\n",
        "# images = []\n",
        "# for file_path in file_paths:\n",
        "#     image_path = os.path.join(data_dir, file_path)\n",
        "#     image = Image.open(image_path).resize(small_shape)\n",
        "#     images.append(np.array(image))\n",
        "\n",
        "labels = df['category'].values\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "Wz5mpVOuw9Sf"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmogOnb-cdzw",
        "outputId": "3b53aee1-eb6b-4042-ce64-d00322b3370f"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['file_name', 'width', 'height', 'x1', 'y1', 'x2', 'y2', 'category'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "L4e9m6PUebZE",
        "outputId": "2e79a00b-495c-4dfa-aae7-c26f80db2283"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[130, 113,  98],\n",
              "        [130, 113,  98],\n",
              "        [129, 112,  97],\n",
              "        ...,\n",
              "        [107,  93,  83],\n",
              "        [106,  93,  82],\n",
              "        [105,  91,  79]],\n",
              "\n",
              "       [[130, 113,  98],\n",
              "        [130, 113,  98],\n",
              "        [128, 113,  97],\n",
              "        ...,\n",
              "        [107,  93,  83],\n",
              "        [106,  92,  82],\n",
              "        [105,  91,  80]],\n",
              "\n",
              "       [[130, 112,  98],\n",
              "        [129, 113,  98],\n",
              "        [129, 113,  98],\n",
              "        ...,\n",
              "        [108,  93,  83],\n",
              "        [106,  92,  82],\n",
              "        [105,  92,  81]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[115,  96,  84],\n",
              "        [114, 101,  86],\n",
              "        [115, 103,  89],\n",
              "        ...,\n",
              "        [ 96,  86,  77],\n",
              "        [ 95,  86,  78],\n",
              "        [ 95,  86,  77]],\n",
              "\n",
              "       [[116,  94,  82],\n",
              "        [115, 100,  86],\n",
              "        [115, 102,  88],\n",
              "        ...,\n",
              "        [ 96,  86,  77],\n",
              "        [ 95,  86,  77],\n",
              "        [ 94,  86,  76]],\n",
              "\n",
              "       [[116,  92,  82],\n",
              "        [114, 100,  86],\n",
              "        [115, 102,  89],\n",
              "        ...,\n",
              "        [ 97,  86,  77],\n",
              "        [ 96,  86,  78],\n",
              "        [ 94,  86,  75]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-9fd512eb-57f9-4927-a2ed-3182a9bc4524\" class=\"ndarray_repr\"><pre>ndarray (48, 48, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAIAAADYYG7QAAAQS0lEQVR4nE152ZJd13Vk5tr73LnmARMLBEAQ5gDKmixatqVu2YpuR3crOqL1pFf/gX/Bn+PQS0d32E92e6YsSqIo0xxEECQAojAUarrTmfZe2Q/nFsP35UZVnTp33bVzZebKw7/48z8DIAkAQZcACEYlAQ5A6hd28Dt3B3ETz5/y/AjeWtuwqQiAEtwl7xcajLwXPRSWM6s6LJdhOWfrBEAnQiKtKLS+5bv7Z2367RcPytRA3V0kSJ4jAAAizAEoCNkEOUBKQWJhV26/Nig29fCLuDhlriCgbVAvFSxvbzdb22m4mXtDWQAgUBDlJo/1MkzPiuePi/MTGDFcs7ry6amlZntz92B3//7TwxbiqggAjBBEEBRByf/DH0WAvHT9xmh8SQ8+D0cPzURIpLxK25vtpYN2fSeDcHM63SmDMkgRGZYHmxhuhp0rvdNn/UefF2fH6A+M0Hzq5+d7+9fq3b0HR88BEt0ZMYIAQKFriwA4ul/KfevypY39W3jyLLx4YtVSgx4ANzXXDpq9G9ki4ObuzBQBCFlwh3Vfl0ogssVy96BZ3x1+9sHw6KkpAkKbWc2u7l5d1tWzs6kBhADvjoyCnAQEKZMGyTUYDfcOXsXZPJwcWlrSJHcFK2++2mxcoigpO8tWFszMopFmBkU51N0Y1jXclXuD8rVvavTp6OGnJEMRw3KeF2fXd3bmZbWoSlASY3c5QJPgcMAoiLC8e/ByyAWefxGW55AAIVh541a9cZmuDIVgn917+Fd/849xUIRef9Dv9/qD/qDo9Qej/mAw7PcH/eGg1+8Xk35/ezygxfL6HQLDB/dMLZV59mK8P7yyvX3vyaFEIseumK43XdcgyjXZ3hxtXdHzk2J5bjmjbV25vH6j2roKN4cgN+P0/PT08H6bc13XJEEKAGgWQowAYIEMN145+MmP/8dgMIJQXn/VmjR6ch9mkDA/29jYWxsOzxZzklEGytXNPUBRkJk2919iJU6PgZzl9NReuVzvXEUH/g5vZNu2oQiM1uZkHX2QRhikVLsAoU2pmU/q5XmvFwILZ1jevBOqRW9+DDK27aBt9re3p8uFxO6IsZotUASk/tpkPN7Nzw5DPe/652vj6uotKUCSRDkgZVVlU1etHBQzJDKYxRhBFDGYmVMyWgz9fs9Ed/fsuSjKg1vZolJrOffrxfpkPB6OhWzQCn+AQYQAYW1rzxzF7MTKGZsa8ubay21/Xe4uXZTk7t7UVdumlBKBIMpd2ZUlV5Ny06bsEtTrRSsGYiAgZU+5Wd+uty/Ds5RDtRyktLG+aWDsJh0yEBAIsRcnGzs8OYnnz8msjDwe1lt7cidAwSXKJYd72zSulDM7ov/a77x8+8puVdV12VZVOa/qqs1l1VxaH0XC3UkZDJKoZv9acXYUUy14r5xORhsx9CJBSGJHPszSeDTuKdrpET2LLqndu5xZyLtrBMnhAiDVbXbAIZeMun33zT96+/ezZwpUzjmn1DZVJZKMoEhCIKCMdjJpNnbC0SGtCGU5HGz0hsPYgVmgi6SkPJpshLJGs1TRQ258GJv17dXnd9WshA9ZaptaIgXIRdJCK+QEkGBEKGT9/mAdUM5JKwbuAOIi250rg6OnTG0gBm25NhpFUQJ0gaMQ4mA44Xxqi3OmGt5qYyNZoGdJ6LoNUSAFuTwBLphAI4sYjOZI3dwaYEAHPKr7n9V7ECDk0VoejkM5hXK/XAwHmwZZp4eEIFjRKyxyMWdqlFvK09o6Q4H/8DKA8O5LpCyAEjveeHYyv3d49GRW1YKZSS4JLl58ZUGguBJUKYY02ex0K9SLARkJdVzmcsljMS6apOV5lhvoIfhwIhiQIanzIwQZBElMnrtb94oYyJ//88/ee/d9Fb3dy5fe+vrdu68cjGNAdtA66iKMcoKZMAi0NFn3I1LOnAfeREEkIHU6HmO02ZTVgkqCvDdIxVDKK3MACODqHXC1KZECO8VBbuvcNm2bzp49fvzbjz984/X/9l9+cHltkiXyAkA0qcMkQPlwLCvojbVtqBYG4StYAAwWfTmXt/TMlBCjh8BuCi+qIUiAgEspZdAA5pzdRZqAEMOgVwwjPnvvvZ/+9H8fTs+jsWssDSRJM4FUJlIssoXOfsWqMmAFtI6DSOS6njWpTFDOMhODgKwVCkQ54TAQ8tw2bWpSahqlbJ6VU3Z3VwgUg5k9uXfvr/7vX8/qmqRrZd8EAMFBlzwEt2DuiNE8R9Ghrj6IHmj9qmK5nLZpo2CQiXCIncvt+M8BQ5sE+ddu7r92bTgZT4oY4V7WzdGLk8dPj8+quq5KukD75IOPfnbr1p/8wdts2o4cIRkUHDKSRod7i8aoFKUL9ZALctHbupid7sYQ2KtTN+3d6ZMgAIfOXpzPTp9dvn7w3T/+fuxFC30IWSnVrTzVs+mnH370dz/79YzZU+6F4qP3P/j2W29sDke5kyc5Ae/chdHNlDORjIxa+TN1H+mATzbMCqVKRqUW7rDQwUdQ0+Tjp8+WJ4+henY22drcaRLhWdnb1BTBQjEY702++f1LboO//rt/Ho+GFuNiNv/y8Mn2nTs5Z0ggLw4fkAxGB5gZYkdC3UUCRPeYUxiNxSAjUkutRh1Qav3ky4fzo89MTW7b0ycPUmogSZ6VqWwhwkJWzhbe/Pa3rl7aS8o559w2jx4+mpVlm1dozIBTAOGe6yVSC8nLOnbM2Q2hBFeGRJCDofV7aBNTq1Cs+pjrrZ3NkM5HaxN35lwVMboZgGDG2CPkSqC5qzccHLz00uNnRynS3Z8dPm4Wx/RYrE36vT4dAQajp8ymcXfmnJZVBDr/q64LZdNW2ccxIgzQHwQX6hKDMQCRRb+vXm9//CZDcM8UxAC5JJIIMVOUiwKcZuvrG97mpmmb1JZ1s76zjyY3bZpP5+PJuPNioamsrZGzq06iCSZ0DEwKUvLCmnKOXh8IbD02DUHDBUHAnJayn1X+vMbcrWVEKADCM1yAyQGXOWDWyNXRCeQC+oMYe2jnRO6IifMlve06m4W4ImmuxDzl7GtrOaOtloPxugGYTcP+gaSUvG2rXq/nUAzxnX945933PxgMBxbD3ddv/fB73wFBOWgGCnBwUdYkCEIoYiTgKdepGW/vGYJBJuP0jDnRQl7WCUVcwXW1clqqmmaybQnmQm5oKGbT5G0Cc26QG1iPTjMWTNPnjxYxwHGfy/L33poMxoQ7CJBUcn/+4sQFMwra2JiYWdsko2DBBdGYMl4cUSDpOTWjcScrXU1ySDkt4I7A6bnnpJzCixdxegaoiLE/mqCbWeDy/l6v17cQBsP+8fHZ4yfPiyKqEzYihDA9Wz548GUn7CHYpUt7NAsx9gZDA9Xp/Wxmp88JuCPRyuHYCMEFqdvIBV/Uc129cr6s67JEVWF2xsdfGABj9xLgyleu7m+uTTpbpjb90z+9czybhyIGQwiUws9+/v70/LhDwnDYe+naJYkygoSDgIHh8EmvnNNb1U3Val70TSCtAxApgKwWi3pvy1nksvK2gpwP7tt8ZiGik1XSXVvbW3du3pR7m7KTjz5/+Jc//T/vfvjZ4Xl5eLz827//xa9++fOiYDCmlK9c2bl8+bJyhvvKcRpZNvHwC2OWPKemDJxaiNCFcnThgqCmnRE76xs2fe79KCmc1fH+J83XvyOKcrgLtBDe/s43Prn327Oyzi65Hnx67/HDR6P1dZPV05OsVmYQY/Tf+9abw8E4Je/4DITB7OGjYnYsSY5q2ZztXVkCJlsBmrhwjtC8XKbr11Pd5rJG4/RU3P80Hj2nRSCCETSXX7lx8MPvfbdP5eyAaPC2WZwcLc6PkrJgntG06a27t964+7spd2RF0KyIYVr27n8UvIXkTZo5pmvrntzkApzIF30CaE1VLTbXsbPvbfLcQM7p1H71rlWld2fWDbbwrT/87o9+8J/We0GQBYKybuqJ5GpTeuP21f/+p/+1iGPACBOIYEqKH3/Qm72QS2B5Pp9ubM5CIJPltskpq9tYL1wzs5+V8/qVV3JGzu4uN+LLL/jrd00Z6FYPOaRQfPsH3//Jj3/0tZevDOHwnHPKrtSmftD33n79f/34f4439lZcJycRGOzfP4mff0Al0FOdZo6Tvct1EoW4nE2H4zFs4DRABjgBYz1fHl26dPngBr98KMiZBYUPf8P+MP3uN5yk3IWcs4LdfOtrL928dXjv08/v3z+ZnTu0tbX5xt3XL924DYtZIuhykDTjx/fi+/9Ca0RD64t5dfzywVkITMlpsT8ciCZ32mqDowSZaGenx6NX74wePymWM+9F0gZQfu8X3jq+/g2PheUMgFDTZIV47fU3D958wzyJLPrD5Mxy+GohNiMy7ON7vV+/E5ole9Hh1bQ8nYyOtvY8ZQpOmcUeQ7iwybmLY1aAatvnVVm++WYlPipTnTKlkJril//K//e3PD1njDQDQIMFE5kUUhh4HLSuLO88tBkVAxa1/esvBu/+QyjPncxZy1l16jq+cbPs7AYgMZIkDKQu8iHiKxPJVC5Pttb7r77+6FfvbwWDGRzmHj78N335GN/4Nl57TYN+lyt2siGQoKsz8wSJNvlnn8d/f2+weI555RT6RVu30za9eO3V02Ki1K5SJSHKheBEXLnUlQ25WHnky9m0uXZ5s1ye3ru34cHMksPJOD3WP/4NPv7Yb7+ar17l5rr6va4Kd5nE1Nps6Y+f6P6nvaePYpGs388wKjeLZq50euf20Wgrt4lc7YYiotwZTLiIGDsgrfaQlQloq+Xg1Vsizj/5pB/NegX7fbWNQeHFl376NAwnHE18fT0NJwrGprWqiotZLGe+nCG3AD1Rljx7tWxmUaevvXK8vtO2iSY6swTrMsYuE+pac+Fk6X6RDFOC3Ktl2bt5o1ybzH7568GimvTdSBEWAyQrZ7Gc6fgwwVrP0RCdMFlhiNYgePYe2dZ+Pp3X4/7Z3deORxveLZkrVu7KQATdFTtBo7xDwEXqsrrOYSavy/LF9s7gu2+njz9unz4bmY0G/dzJrSCzLCRkMxSMCgAFM1nxMFrb5q3ZQnW9vLa7uH37zHrKabXLyny1roGy6BfJWQceqQsSKHh3ZJIuYm2kqpr3e4NvfjM9eVp98WB5ctaHhoN+iKFFAuhQEUOCHNnI7GqbOia2OU0n/ebOy8ud3ToLKeNigRdEyBxOOBTNgSBAnbHSCj5dCqyL/FFd1EkQKVfZbX8n7u6001l1eDh9/iIsKrRNJAzBYlCMSZ5dGg5Jpr2NZnernKyl0EPKoDvDV7v5yhpS3SOCuArESMo6R9StKS4YLsq6SLU62SOQc3awXl8P21sxpzu7wyvZTx99+fTps7MqVwiNFXFt5FvbKmIbQ8oZGcjdRkV2Xb/IwC6mySBFukOrj149YNDqJ0d3CAAEZya9Swwutkp6zrlt4bf+9Ec//M8/UXVy/6NfvPPOv/3mNx+cn7/o9Uc5u7qnCFxRlFZbK77qD9mBtYvNZKstqKMyOKVVfNjN3YoguicZMLFbKS467SQIb+oKIPub/e3rk/2Xt7YvFwwpJb8wEfgqlOSqmovgYSUtvEh5/j+mEfBOoDG8EQAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[130, 113,  98],\n",
              "        [130, 113,  98],\n",
              "        [129, 112,  97],\n",
              "        ...,\n",
              "        [107,  93,  83],\n",
              "        [106,  93,  82],\n",
              "        [105,  91,  79]],\n",
              "\n",
              "       [[130, 113,  98],\n",
              "        [130, 113,  98],\n",
              "        [128, 113,  97],\n",
              "        ...,\n",
              "        [107,  93,  83],\n",
              "        [106,  92,  82],\n",
              "        [105,  91,  80]],\n",
              "\n",
              "       [[130, 112,  98],\n",
              "        [129, 113,  98],\n",
              "        [129, 113,  98],\n",
              "        ...,\n",
              "        [108,  93,  83],\n",
              "        [106,  92,  82],\n",
              "        [105,  92,  81]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[115,  96,  84],\n",
              "        [114, 101,  86],\n",
              "        [115, 103,  89],\n",
              "        ...,\n",
              "        [ 96,  86,  77],\n",
              "        [ 95,  86,  78],\n",
              "        [ 95,  86,  77]],\n",
              "\n",
              "       [[116,  94,  82],\n",
              "        [115, 100,  86],\n",
              "        [115, 102,  88],\n",
              "        ...,\n",
              "        [ 96,  86,  77],\n",
              "        [ 95,  86,  77],\n",
              "        [ 94,  86,  76]],\n",
              "\n",
              "       [[116,  92,  82],\n",
              "        [114, 100,  86],\n",
              "        [115, 102,  89],\n",
              "        ...,\n",
              "        [ 97,  86,  77],\n",
              "        [ 96,  86,  78],\n",
              "        [ 94,  86,  75]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-9fd512eb-57f9-4927-a2ed-3182a9bc4524 button').onclick = (e) => {\n",
              "        document.querySelector('#id-9fd512eb-57f9-4927-a2ed-3182a9bc4524').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-9fd512eb-57f9-4927-a2ed-3182a9bc4524 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "оставим только заданные типы знаков"
      ],
      "metadata": {
        "id": "52N8tEgMycP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remain=[3,4,5,7,11,16,17,26,30,35,43,55]\n",
        "a=[index for index,value in enumerate(labels) if value in remain]\n",
        "inds=np.array(a, dtype=int)\n",
        "\n",
        "images = images[inds]\n",
        "labels = labels[inds]"
      ],
      "metadata": {
        "id": "62fcsJCRxgXp"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_dict = {value: index for index, value in enumerate(remain)}\n",
        "labels=[index_dict[v] for v in labels]\n",
        "\n",
        "num_classes = len(remain)\n",
        "labels = to_categorical(labels, num_classes=num_classes)\n",
        "# labels = tf.one_hot(labels.astype(np.int32), depth=num_classes)"
      ],
      "metadata": {
        "id": "R_1f89Hk5Yd0"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = images / 255"
      ],
      "metadata": {
        "id": "a7XGk4h606QZ"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[-10:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax_WElsuIgXo",
        "outputId": "9f1cd1a0-aa1f-48f5-ce27-99e346ba59d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "XGSkAnhszcLe"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomTranslation(0.05, 0.05),\n",
        "  # layers.RandomZoom((-0.3, -0.1)),\n",
        "  layers.RandomRotation(0.1),\n",
        "  layers.RandomContrast(0.1),\n",
        "  # layers.RandomBrightness(0.1)\n",
        "])"
      ],
      "metadata": {
        "id": "KF1bI-Pzysv1"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NwCF10WSjQRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomZoom нужен если не обрезать знаки по коордианатам. увеличение RandomBrightness приводит к кратному уменьшению val_acc"
      ],
      "metadata": {
        "id": "7wwFZCMeia0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    data_augmentation,\n",
        "    tf.keras.layers.Conv2D(32, (3,3), strides=(1,1),\n",
        "                                      padding='same',\n",
        "                                      activation='relu',\n",
        "                                      input_shape=(small_shape[0], small_shape[1], 3)),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), strides=(1,1),\n",
        "                                      padding='same',\n",
        "                                      activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), strides=(1,1),\n",
        "                                  padding='same',\n",
        "                                  activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "h1UwgaWAOcVM"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-7к примерно. добавление dence ухудшает"
      ],
      "metadata": {
        "id": "uTZ-uFmpi5Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "p2TJFfctAV4f"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=20\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlP27bYE19oW",
        "outputId": "1a8f9191-37b8-4f5b-fda1-65f31172bb41"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 222ms/step - acc: 0.2224 - loss: 2.1614 - val_acc: 0.4779 - val_loss: 1.2992\n",
            "Epoch 2/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 206ms/step - acc: 0.4660 - loss: 1.3424 - val_acc: 0.5498 - val_loss: 1.0747\n",
            "Epoch 3/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 278ms/step - acc: 0.5734 - loss: 1.0318 - val_acc: 0.6494 - val_loss: 0.7910\n",
            "Epoch 4/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 230ms/step - acc: 0.6511 - loss: 0.8371 - val_acc: 0.7657 - val_loss: 0.5569\n",
            "Epoch 5/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 224ms/step - acc: 0.7568 - loss: 0.6046 - val_acc: 0.8561 - val_loss: 0.4190\n",
            "Epoch 6/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - acc: 0.8350 - loss: 0.4381 - val_acc: 0.8690 - val_loss: 0.3500\n",
            "Epoch 7/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - acc: 0.8561 - loss: 0.3984 - val_acc: 0.9354 - val_loss: 0.2407\n",
            "Epoch 8/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 260ms/step - acc: 0.8850 - loss: 0.3107 - val_acc: 0.9391 - val_loss: 0.2160\n",
            "Epoch 9/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 235ms/step - acc: 0.9196 - loss: 0.2019 - val_acc: 0.9576 - val_loss: 0.1662\n",
            "Epoch 10/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 211ms/step - acc: 0.9463 - loss: 0.1726 - val_acc: 0.9557 - val_loss: 0.1455\n",
            "Epoch 11/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - acc: 0.9473 - loss: 0.1516 - val_acc: 0.9520 - val_loss: 0.1443\n",
            "Epoch 12/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 209ms/step - acc: 0.9596 - loss: 0.1209 - val_acc: 0.9649 - val_loss: 0.1323\n",
            "Epoch 13/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 208ms/step - acc: 0.9688 - loss: 0.1170 - val_acc: 0.9686 - val_loss: 0.1138\n",
            "Epoch 14/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 209ms/step - acc: 0.9825 - loss: 0.0775 - val_acc: 0.9760 - val_loss: 0.1389\n",
            "Epoch 15/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - acc: 0.9729 - loss: 0.0754 - val_acc: 0.9797 - val_loss: 0.1543\n",
            "Epoch 16/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - acc: 0.9687 - loss: 0.0945 - val_acc: 0.9668 - val_loss: 0.1195\n",
            "Epoch 17/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - acc: 0.9729 - loss: 0.0939 - val_acc: 0.9834 - val_loss: 0.0949\n",
            "Epoch 18/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 212ms/step - acc: 0.9821 - loss: 0.0587 - val_acc: 0.9760 - val_loss: 0.1226\n",
            "Epoch 19/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 201ms/step - acc: 0.9803 - loss: 0.0727 - val_acc: 0.9852 - val_loss: 0.1244\n",
            "Epoch 20/20\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - acc: 0.9850 - loss: 0.0468 - val_acc: 0.9797 - val_loss: 0.1351\n"
          ]
        }
      ]
    }
  ]
}