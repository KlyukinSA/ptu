{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfNT-mlFwxVM"
      },
      "source": [
        "# Intro to Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITZuApL56Mny"
      },
      "source": [
        "Выявление аномалии с помощью автокодировщика.\n",
        "Построить автокодировщик, позволяющий выявить в картинках одежды (база fashion_mnist) аномалии. В качестве аномальных картинок использовать рукописные цифры (база mnist). Автокодировщик должен детектировать подаваемые на него рукописные цифры как аномальные, а подаваемые на него элементы одежды как нормальные.\n",
        "https://www.tensorflow.org/tutorials/generative/autoencoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "## Load the dataset\n",
        "To start, you will train the basic autoencoder using the Fashion MNIST dataset. Each image in this dataset is 28x28 pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZm503-I_tji"
      },
      "outputs": [],
      "source": [
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "print (x_train.shape)\n",
        "print (x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEdCXSwCoKok"
      },
      "source": [
        "## First example: Basic autoencoder\n",
        "![Basic autoencoder results](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/intro_autoencoder_result.png?raw=1)\n",
        "\n",
        "Define an autoencoder with two Dense layers: an `encoder`, which compresses the images into a 64 dimensional latent vector, and a `decoder`, that reconstructs the original image from the latent space.\n",
        "\n",
        "To define your model, use the [Keras Model Subclassing API](https://www.tensorflow.org/guide/keras/custom_layers_and_models).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MUxidpyChjX"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(Model):\n",
        "  def __init__(self, latent_dim, shape):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.shape = shape\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(latent_dim, activation='relu'),\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(tf.math.reduce_prod(shape).numpy(), activation='sigmoid'),\n",
        "      layers.Reshape(shape)\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "\n",
        "shape = x_test.shape[1:]\n",
        "latent_dim = 64\n",
        "autoencoder = Autoencoder(latent_dim, shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.reduce_prod(shape).numpy() == (shape[0]*shape[1])"
      ],
      "metadata": {
        "id": "-3zHaP0uU0T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I1JlqEIDCI4"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oJSeMTroABs"
      },
      "source": [
        "Train the model using `x_train` as both the input and the target. The `encoder` will learn to compress the dataset from 784 dimensions to the latent space, and the `decoder` will learn to reconstruct the original images.\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1RI9OfHDBsK"
      },
      "outputs": [],
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=8,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(anomalous_x_train, _), (anomalous_x_test, _) = mnist.load_data()"
      ],
      "metadata": {
        "id": "IWueIirIf3KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anomalous_x_train = anomalous_x_train.astype('float32') / 255.\n",
        "anomalous_x_test = anomalous_x_test.astype('float32') / 255."
      ],
      "metadata": {
        "id": "yGxepC9KgxmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.title(\"original + noise\")\n",
        "    plt.imshow(tf.squeeze(anomalous_x_train[i]))\n",
        "    plt.gray()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fCvu8xeEhJVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocimg3MBswdS"
      },
      "source": [
        "### Detect anomalies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = autoencoder.predict(x_test)\n",
        "ss=x_test.shape[0]\n",
        "loss = tf.keras.losses.mae(reconstructions.flatten().reshape((ss, -1)), x_test.flatten().reshape((ss, -1)))\n",
        "\n",
        "plt.hist(loss, bins=50)\n",
        "plt.xlabel(\"normal test loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZFn3cVfPiah2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape, reconstructions.shape, loss.shape"
      ],
      "metadata": {
        "id": "2rMznj25jddS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh-3ChEF5hog"
      },
      "source": [
        "Choose a threshold value that is one standard deviations above the mean."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.mean(loss) + np.std(loss)\n",
        "threshold, np.mean(loss), np.std(loss)"
      ],
      "metadata": {
        "id": "cRYzqBjfoH2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anomalous_x_test.shape"
      ],
      "metadata": {
        "id": "pEP7ymebmqEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rake_anomalous_x_test = anomalous_x_test[..., tf.newaxis]\n",
        "ano_reconstructions = autoencoder.predict(anomalous_x_test)\n",
        "ano_ss=anomalous_x_test.shape[0]\n",
        "ano_loss = tf.keras.losses.mae(ano_reconstructions.flatten().reshape((ano_ss, -1)), anomalous_x_test.flatten().reshape((ano_ss, -1)))\n",
        "\n",
        "plt.hist(ano_loss, bins=50)\n",
        "plt.xlabel(\"anomaly loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tptAmZ_RmUR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(ano_loss), np.std(ano_loss)"
      ],
      "metadata": {
        "id": "RtxWyfR_oY1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_classification_init(a1, a2):\n",
        "  return np.concatenate((a1, a2), axis=0), np.concatenate((np.full(a1.shape[0], 0), np.full(a2.shape[0], 1)), axis=0)\n",
        "make_classification_init(np.array([[1,2],[2,3]]), np.array([[3,4],[4,5]]))"
      ],
      "metadata": {
        "id": "IA9P_TCPtJXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape, anomalous_x_test.shape"
      ],
      "metadata": {
        "id": "VJ6kwzD_vJdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = plt.subplot(1, 2, 1)\n",
        "plt.title(\"norm\")\n",
        "plt.imshow(tf.squeeze(x_test[i]))\n",
        "plt.gray()\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "plt.title(\"anomaly\")\n",
        "plt.imshow(tf.squeeze(anomalous_x_test[i]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e1B2kwD5vPrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification_init(x_test, anomalous_x_test)"
      ],
      "metadata": {
        "id": "cEe_CUYgzTGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = autoencoder(X)"
      ],
      "metadata": {
        "id": "_yMOhFWLrIt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss=reconstructions.shape[0]\n",
        "loss = tf.keras.losses.mae(np.array(reconstructions).flatten().reshape((ss, -1)), np.array(X).flatten().reshape((ss, -1)))"
      ],
      "metadata": {
        "id": "lUCJPWbuwrvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.shape"
      ],
      "metadata": {
        "id": "OOFrr1Uk5pcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(loss, bins=50)\n",
        "plt.xlabel(\"mixed test loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fQ0EHL0U55Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = tf.math.less(threshold, loss)"
      ],
      "metadata": {
        "id": "gmHlN3i551ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy = {}\".format(accuracy_score(y, preds)))"
      ],
      "metadata": {
        "id": "qI9GPFHw6GXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Использован кодировщик с одним полносвязным слоем, выдающий 64 признака. Декодировщикк симметричен. Порог аномалии выбран как одна сигма от среднего значения ошибки нормальной картинки.\n",
        "\n",
        "Получается с точностью 87% отличить на картинке элемент одежды от аномалии, которая в данном случае является рукописной цифрой\n",
        "\n",
        "В качестве улучшения можно увеличивать количество нейронов, вводить сверточные слои и искать оптимальные количество признаков и порог аномалии"
      ],
      "metadata": {
        "id": "NNzlbPHv8RuQ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}